{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "193CCJ_kbDDe",
        "outputId": "8e323372-a383-4955-8b66-cdb16c4d3192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.10/dist-packages (6.0.11)\n",
            "Collecting pandas_market_calendars\n",
            "  Downloading pandas_market_calendars-4.4.2-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser) (1.0.0)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from pandas_market_calendars) (2.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from pandas_market_calendars) (2024.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from pandas_market_calendars) (2.8.2)\n",
            "Collecting exchange-calendars>=3.3 (from pandas_market_calendars)\n",
            "  Downloading exchange_calendars-4.5.8-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from exchange-calendars>=3.3->pandas_market_calendars) (1.26.4)\n",
            "Collecting pyluach (from exchange-calendars>=3.3->pandas_market_calendars)\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from exchange-calendars>=3.3->pandas_market_calendars) (0.12.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from exchange-calendars>=3.3->pandas_market_calendars) (2024.2)\n",
            "Collecting korean-lunar-calendar (from exchange-calendars>=3.3->pandas_market_calendars)\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->pandas_market_calendars) (1.16.0)\n",
            "Downloading pandas_market_calendars-4.4.2-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exchange_calendars-4.5.8-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.8/196.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: korean-lunar-calendar, pyluach, exchange-calendars, pandas_market_calendars\n",
            "Successfully installed exchange-calendars-4.5.8 korean-lunar-calendar-0.3.1 pandas_market_calendars-4.4.2 pyluach-2.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install feedparser pandas_market_calendars"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import feedparser\n",
        "from datetime import datetime, timedelta\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "import pandas_market_calendars as mcal"
      ],
      "metadata": {
        "id": "eb0DTGE7bKv5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download VADER lexicon\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJFd6bFmbVzR",
        "outputId": "1cb1bd25-e402-46e2-8aa4-68bea15e9b88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize VADER SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "Xxbq-53hbbm2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get sentiment score\n",
        "def get_sentiment_score(text):\n",
        "    return sia.polarity_scores(text)['compound']"
      ],
      "metadata": {
        "id": "PikeCt9CbwNi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate date range for the past 2 years (excluding today's date)\n",
        "def generate_date_range():\n",
        "    end_date = datetime.now() - timedelta(days=1)\n",
        "    start_date = end_date - timedelta(days=2*365)\n",
        "    return pd.date_range(start=start_date, end=end_date)"
      ],
      "metadata": {
        "id": "gXlz4uOMbzQo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fetch headlines for a given date from Yahoo Finance RSS feed for a specific stock ticker\n",
        "def fetch_headlines(date, stock):\n",
        "    url = f\"https://finance.yahoo.com/rss/headline?s={stock}\"\n",
        "    feed = feedparser.parse(url)\n",
        "    headlines = [\n",
        "        entry.title for entry in feed.entries\n",
        "        if datetime(*entry.published_parsed[:6]).date() == date.date()\n",
        "    ]\n",
        "    return headlines"
      ],
      "metadata": {
        "id": "feOpVQ0db1cm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fill missing sentiment scores with backward interpolation\n",
        "def fill_missing_scores(df):\n",
        "    df['Sentiment'] = df['Sentiment'].interpolate(method='linear', limit_direction='backward')\n",
        "    return df"
      ],
      "metadata": {
        "id": "eAaEVq02b3PT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to adjust historical prices for stock splits\n",
        "def adjust_for_splits(hist):\n",
        "    splits = hist['Stock Splits']\n",
        "    for date, split in splits[splits != 0].items():\n",
        "        hist.loc[:date, 'Close'] /= split\n",
        "    return hist"
      ],
      "metadata": {
        "id": "d2Qhz5fyb5B-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trading_days():\n",
        "    nyse = mcal.get_calendar('NYSE')\n",
        "    schedule = nyse.schedule(start_date=(datetime.now() - timedelta(days=2*365)).strftime('%Y-%m-%d'),\n",
        "                              end_date=(datetime.now() + timedelta(days=30)).strftime('%Y-%m-%d'))\n",
        "    return schedule.index.to_pydatetime()\n"
      ],
      "metadata": {
        "id": "_vGS-9WJcy0l"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get stock ticker from user\n",
        "stock = input(\"Enter the stock ticker: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU5m0uUTb6_M",
        "outputId": "524b6575-be30-4d7e-d7a9-d982023bee50"
      },
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the stock ticker: AAPL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch historical stock data for the past 2 years (excluding today's date)\n",
        "stock_data = yf.Ticker(stock)\n",
        "hist = stock_data.history(start=(datetime.now() - timedelta(days=2*365)), end=(datetime.now() - timedelta(days=1)))\n"
      ],
      "metadata": {
        "id": "B3OZiPNgb8wP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust historical prices for stock splits\n",
        "hist = adjust_for_splits(hist)"
      ],
      "metadata": {
        "id": "6VSNlDCCb_1-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate date range for the past 2 years (excluding today's date)\n",
        "date_range = generate_date_range()"
      ],
      "metadata": {
        "id": "rXyre_-7cBiH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with dates\n",
        "df = pd.DataFrame(date_range, columns=['Date'])\n",
        "df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
        "df.set_index('Date', inplace=True)"
      ],
      "metadata": {
        "id": "5Otvm0w0cDG6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Sentiment Scores\n",
        "df['Headlines'] = df.index.to_series().apply(lambda date: fetch_headlines(datetime.strptime(date, '%Y-%m-%d'), stock))\n",
        "df['Sentiment'] = df['Headlines'].apply(lambda headlines: get_sentiment_score(' '.join(headlines)) if headlines else None)\n",
        "df = fill_missing_scores(df)"
      ],
      "metadata": {
        "id": "dBXNqNwIcI4t"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add closing prices to the DataFrame\n",
        "# Convert the index to DatetimeIndex if it's not already\n",
        "hist.index = pd.to_datetime(hist.index)\n",
        "hist['Date'] = hist.index.strftime('%Y-%m-%d')\n",
        "hist.set_index('Date', inplace=True)\n",
        "df['Close'] = hist['Close']"
      ],
      "metadata": {
        "id": "TK1ngtYCdNG8"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpolate missing closing prices\n",
        "df['Close'] = df['Close'].interpolate(method='linear', limit_direction='backward').interpolate(method='linear', limit_direction='forward')\n",
        "df = df[['Close', 'Sentiment']]"
      ],
      "metadata": {
        "id": "FncRz3AujToc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill any remaining NaN values in closing prices with forward interpolation as a fallback\n",
        "df['Close'] = df['Close'].interpolate(method='linear', limit_direction='forward')\n",
        "\n",
        "# Remove the Headlines column and keep only Date, Closing Price, Sentiment Score\n",
        "df = df[['Close', 'Sentiment']]"
      ],
      "metadata": {
        "id": "gHda0MlskTAJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the closing prices and sentiment scores\n",
        "scaler = StandardScaler()\n",
        "df[['Close', 'Sentiment']] = scaler.fit_transform(df[['Close', 'Sentiment']])"
      ],
      "metadata": {
        "id": "Aj_LfbMfkYNG"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Features and Labels\n",
        "X = df[['Close', 'Sentiment']].values\n",
        "\n",
        "train_size = int(len(X) * 0.8)\n",
        "train, test = X[:train_size], X[train_size:]\n",
        "\n",
        "train_X, train_y = train[:-1], train[1:, 0]\n",
        "test_X, test_y = test[:-1], test[1:, 0]\n",
        "\n",
        "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
        "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n"
      ],
      "metadata": {
        "id": "S6JSXN6GkfAo"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.fit(train_X, train_y, epochs=50, batch_size=32, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8KEvzRlkpPi",
        "outputId": "9157bbe7-37de-4def-a14a-2f06aaa1a4ff"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "19/19 - 3s - 155ms/step - loss: 0.6214 - val_loss: 2.5165\n",
            "Epoch 2/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.5730 - val_loss: 2.4611\n",
            "Epoch 3/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.5338 - val_loss: 2.4070\n",
            "Epoch 4/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.4961 - val_loss: 2.3520\n",
            "Epoch 5/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.4590 - val_loss: 2.2934\n",
            "Epoch 6/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.4223 - val_loss: 2.2283\n",
            "Epoch 7/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.3860 - val_loss: 2.1540\n",
            "Epoch 8/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.3498 - val_loss: 2.0682\n",
            "Epoch 9/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.3136 - val_loss: 1.9693\n",
            "Epoch 10/50\n",
            "19/19 - 0s - 5ms/step - loss: 0.2777 - val_loss: 1.8562\n",
            "Epoch 11/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.2427 - val_loss: 1.7289\n",
            "Epoch 12/50\n",
            "19/19 - 0s - 5ms/step - loss: 0.2088 - val_loss: 1.5895\n",
            "Epoch 13/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.1767 - val_loss: 1.4399\n",
            "Epoch 14/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.1467 - val_loss: 1.2832\n",
            "Epoch 15/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.1194 - val_loss: 1.1234\n",
            "Epoch 16/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.0951 - val_loss: 0.9653\n",
            "Epoch 17/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.0740 - val_loss: 0.8135\n",
            "Epoch 18/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.0563 - val_loss: 0.6725\n",
            "Epoch 19/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.0419 - val_loss: 0.5465\n",
            "Epoch 20/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.0307 - val_loss: 0.4380\n",
            "Epoch 21/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.0223 - val_loss: 0.3481\n",
            "Epoch 22/50\n",
            "19/19 - 0s - 8ms/step - loss: 0.0163 - val_loss: 0.2764\n",
            "Epoch 23/50\n",
            "19/19 - 0s - 8ms/step - loss: 0.0123 - val_loss: 0.2211\n",
            "Epoch 24/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.0097 - val_loss: 0.1797\n",
            "Epoch 25/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.0081 - val_loss: 0.1495\n",
            "Epoch 26/50\n",
            "19/19 - 0s - 8ms/step - loss: 0.0072 - val_loss: 0.1278\n",
            "Epoch 27/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.0067 - val_loss: 0.1124\n",
            "Epoch 28/50\n",
            "19/19 - 0s - 8ms/step - loss: 0.0065 - val_loss: 0.1016\n",
            "Epoch 29/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.0063 - val_loss: 0.0940\n",
            "Epoch 30/50\n",
            "19/19 - 0s - 5ms/step - loss: 0.0063 - val_loss: 0.0886\n",
            "Epoch 31/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.0062 - val_loss: 0.0848\n",
            "Epoch 32/50\n",
            "19/19 - 0s - 6ms/step - loss: 0.0062 - val_loss: 0.0821\n",
            "Epoch 33/50\n",
            "19/19 - 0s - 11ms/step - loss: 0.0062 - val_loss: 0.0801\n",
            "Epoch 34/50\n",
            "19/19 - 0s - 14ms/step - loss: 0.0062 - val_loss: 0.0786\n",
            "Epoch 35/50\n",
            "19/19 - 0s - 10ms/step - loss: 0.0062 - val_loss: 0.0775\n",
            "Epoch 36/50\n",
            "19/19 - 0s - 16ms/step - loss: 0.0062 - val_loss: 0.0765\n",
            "Epoch 37/50\n",
            "19/19 - 0s - 15ms/step - loss: 0.0062 - val_loss: 0.0758\n",
            "Epoch 38/50\n",
            "19/19 - 0s - 19ms/step - loss: 0.0062 - val_loss: 0.0751\n",
            "Epoch 39/50\n",
            "19/19 - 0s - 14ms/step - loss: 0.0061 - val_loss: 0.0745\n",
            "Epoch 40/50\n",
            "19/19 - 0s - 17ms/step - loss: 0.0061 - val_loss: 0.0739\n",
            "Epoch 41/50\n",
            "19/19 - 0s - 10ms/step - loss: 0.0061 - val_loss: 0.0734\n",
            "Epoch 42/50\n",
            "19/19 - 0s - 9ms/step - loss: 0.0061 - val_loss: 0.0728\n",
            "Epoch 43/50\n",
            "19/19 - 0s - 14ms/step - loss: 0.0061 - val_loss: 0.0723\n",
            "Epoch 44/50\n",
            "19/19 - 0s - 5ms/step - loss: 0.0061 - val_loss: 0.0718\n",
            "Epoch 45/50\n",
            "19/19 - 0s - 8ms/step - loss: 0.0061 - val_loss: 0.0713\n",
            "Epoch 46/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.0060 - val_loss: 0.0708\n",
            "Epoch 47/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.0060 - val_loss: 0.0703\n",
            "Epoch 48/50\n",
            "19/19 - 0s - 5ms/step - loss: 0.0060 - val_loss: 0.0698\n",
            "Epoch 49/50\n",
            "19/19 - 0s - 5ms/step - loss: 0.0060 - val_loss: 0.0694\n",
            "Epoch 50/50\n",
            "19/19 - 0s - 7ms/step - loss: 0.0060 - val_loss: 0.0689\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f679b49e7a0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of trading days to predict from user\n",
        "n_days = int(input(\"Enter the number of trading days to predict: \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN-h92YWkvMU",
        "outputId": "7dc81338-cb06-4f96-815e-bb91a03d94e8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the number of trading days to predict: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for trading days\n",
        "trading_days = get_trading_days()\n",
        "future_predictions_scaled = []\n",
        "last_sequence_scaled = X[-1].reshape((1, 1, X.shape[1]))\n",
        "\n",
        "predicted_dates = []\n",
        "for current_date in trading_days:\n",
        "    if len(future_predictions_scaled) >= n_days:\n",
        "        break\n",
        "\n",
        "    next_pred_scaled = model.predict(last_sequence_scaled)\n",
        "    future_predictions_scaled.append(next_pred_scaled[0][0])\n",
        "    predicted_dates.append(current_date.strftime('%Y-%m-%d'))\n",
        "\n",
        "    last_sequence_scaled = np.concatenate([last_sequence_scaled[:, :, 1:], next_pred_scaled.reshape(1, 1, 1)], axis=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I1xfUKSk2d-",
        "outputId": "8f416c8f-88e7-44e1-a824-adba16f2761c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform back to Original Scale\n",
        "future_predictions_scaled_array = np.array(future_predictions_scaled).reshape(-1, 1)\n",
        "future_predictions_original_array = scaler.inverse_transform(\n",
        "    np.concatenate((future_predictions_scaled_array, np.zeros_like(future_predictions_scaled_array)), axis=1)\n",
        ")[:, 0]\n"
      ],
      "metadata": {
        "id": "dOqB3Chtk8Us"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dispaly Predictions\n",
        "print(f\"Predicted closing prices for the next {n_days} trading days:\")\n",
        "for date, price in zip(predicted_dates, future_predictions_original_array):\n",
        "    print(f\"{date}: {price:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nmoc_BdlBph",
        "outputId": "00286183-9d69-4a09-9688-1bff9700d8a6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted closing prices for the next 5 trading days:\n",
            "2022-11-21: 220.74\n",
            "2022-11-22: 184.39\n",
            "2022-11-23: 215.00\n",
            "2022-11-25: 185.81\n",
            "2022-11-28: 210.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of trading days to predict from user\n",
        "n_days = int(input(\"Enter the number of trading days to predict: \"))\n",
        "\n",
        "\n",
        "# Filter for trading days\n",
        "trading_days = get_trading_days()\n",
        "future_predictions_scaled = []\n",
        "last_sequence_scaled = X[-1].reshape((1, 1, X.shape[1]))\n",
        "\n",
        "\n",
        "predicted_dates = []\n",
        "for current_date in trading_days:\n",
        "    if len(future_predictions_scaled) >= n_days:\n",
        "        break\n",
        "\n",
        "    next_pred_scaled = model.predict(last_sequence_scaled)\n",
        "    future_predictions_scaled.append(next_pred_scaled[0][0])\n",
        "    predicted_dates.append(current_date.strftime('%Y-%m-%d'))\n",
        "\n",
        "    last_sequence_scaled = np.concatenate([last_sequence_scaled[:, :, 1:], next_pred_scaled.reshape(1, 1, 1)], axis=2)\n",
        "\n",
        "\n",
        "# Transform back to Original Scale\n",
        "future_predictions_scaled_array = np.array(future_predictions_scaled).reshape(-1, 1)\n",
        "future_predictions_original_array = scaler.inverse_transform(\n",
        "    np.concatenate((future_predictions_scaled_array, np.zeros_like(future_predictions_scaled_array)), axis=1)\n",
        ")[:, 0]\n",
        "\n",
        "\n",
        "#Dispaly Predictions\n",
        "print(f\"Predicted closing prices for the next {n_days} trading days:\")\n",
        "for date, price in zip(predicted_dates, future_predictions_original_array):\n",
        "    print(f\"{date}: {price:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvB9Qn6LlHUt",
        "outputId": "c5b2d490-a5d7-4a4f-b42f-13d31425ad65"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of trading days to predict: 20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Predicted closing prices for the next 20 trading days:\n",
            "2022-11-21: 220.74\n",
            "2022-11-22: 184.39\n",
            "2022-11-23: 215.00\n",
            "2022-11-25: 185.81\n",
            "2022-11-28: 210.82\n",
            "2022-11-29: 187.20\n",
            "2022-11-30: 207.86\n",
            "2022-12-01: 188.55\n",
            "2022-12-02: 205.82\n",
            "2022-12-05: 189.84\n",
            "2022-12-06: 204.42\n",
            "2022-12-07: 191.06\n",
            "2022-12-08: 203.43\n",
            "2022-12-09: 192.18\n",
            "2022-12-12: 202.73\n",
            "2022-12-13: 193.21\n",
            "2022-12-14: 202.19\n",
            "2022-12-15: 194.14\n",
            "2022-12-16: 201.75\n",
            "2022-12-19: 194.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CdrskC_ll_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}